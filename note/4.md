# 三、第三天笔记

## 1.1 昨天回顾

昨天先讲了怎么把代码上传到github上，我们把昨天的新代码也更新上去。

先查看一下有哪些新代码和修改过的代码

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/HJ9LkBbmFl.png?imageslim)

发现有好多新文件和被修改过的文件。

正常公司代码管理流程是，下班前把自己的代码先提交上github上，然后第二天，再把整套代码push下来

然后再进行今天的开发工作。

我们先把这些添加到本地仓库中。用的是git add

$ git add README.md
$ git add conf/
$ git add controllers/
$ git add models/
$ git add routers/
$ git add main.go

然后查看一下状态git status

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/854CCkH8j1.png?imageslim)

发现都添加成功了。下一步是添加更新日志commit

git commit -a -m "20180620更新了注册和数据库操作功能"

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/l36Hedaj23.png?imageslim)

最后再用git push origin master将代码传上去

git push origin master

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/hh6k3JKhBF.png?imageslim)

然后去github仓库中看一下更新成功没有？

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/KchccfHcb2.png?imageslim)

已经更新成功啦。备注信息已经变更了。

然后就可以下班回家啦，然后第二天上班，可以吃着早餐把整个项目，包括同事的push的项目，整套pull下来。再进行调试。等于每天都要搭一遍环境。如果你早上不pull一遍最新代码，到晚上会提交不了代码的。会提示你的代码不是最新代码。因为，首先要保证你本机的版本与远程仓库上的版本要一致，一致了才能进行开发嘛。否则版本不一样的，再懒也写了很多代码，你再把今天写的代码和以前的代码进行融合，那晚上就加班吧。就因为早上少干一件事，没pull代码，可能你就要加班了。

刚才我们push后，我们看一下本地仓库状态。git status

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/8FlciJIilK.png?imageslim)

发现还有一些没用过的文件。这些我们不用管。从来就没改过。没用过。不用上传。

## 1.2 登录业务流程分析

看一下登录模块的设计流程

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/m89BHEklia.png?imageslim)

用的是POST方法，要的数据是

{
​	mobile:"133",
	password:itcast
}

然后看一下业务流程。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/F2I2FmcHG5.png?imageslim)

流程图分析：

1 首先路由去访问/api/v1.0/sessions，就是输入用户名密码点登录，然后post发用户名和密码到去处理，

2 处理后得到用户信息，其实就是session，

3 接下来需要检验用户信息的合法性，就是一般插入数据之前都会限制一下允许插入最大长度的字符，因为有一种叫数据库溢出攻击，就是我一直写，前台页面也不提示，这样写的就很长很长的内容就会插入到数据库里面，就溢出了，就变成0或者负数，这样的话数据库就瘫痪了。一般我们插入数据库之前都会先判断一下输入的内容是否合法。比如手机号，长度是不是太长，太短，必须全部为数字。这个匹配一般我们用正则匹配。密码一般限制多少位多少位。需要做一下限制。

4 拿用户信息去数据库里查询，用mobile去数据库查找 

5 看一下密码是否匹配，

6 如果匹配就给添加上session.登录后是不是要设置session,登录后肯定是要设置session的。要不然没法保持登录状态。昨天只设置了一个，name,因为注册后返回给前端的数据只需要一个name就行。昨天写注册的时候，应该session设置三个字段 。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/9mIJ4jAHai.png?imageslim)

一会一起写上。mobile就是name，注册的时候用的手机号注册的，user_id就是在注册后插入数据库的时候会返回值一个id给我们，那个就是user_id，mobile就是把key值替换成mobile就是了。一样的

## 1.3 登录代码实现

我们把项目跑起来。bee run

我们要来做登录，我们主要是看一下登录后开发者工具哪里红，我们就需要解决哪里。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/FDGA0gE6EC.png?imageslim)

需要的请求是

1. Request URL: http://localhost:8899/api/v1.0/sessions
2. Request Method: POST

看一下，请求，不是session，而是sessions，后面多个s。所以不存在冲突功能。

```
/api/v1.0/sessions
```

先加一条新路由，用作登录处理。

```
beego.Router("/api/v1.0/sessions", &controllers.SessionController{},"post:Login")
```

然后在session.go里创建方法Login()用来实现登录处理

```go
func (this *SessionController) Login() {
   //1.得到用户信息
   resp:=make(map[string]interface{})
   defer this.RetData(resp)
   //获取前端传过来的json数据
   json.Unmarshal(this.Ctx.Input.RequestBody, &resp)
   beego.Info("======name =",resp["mobile"])
   beego.Info("======password =",resp["password"])
   //2.判断是否合法
   //3.与数据库匹配，判断帐号密码是否正确
   //4.添加session
   //5.返回json数据给前端
}
```

一般我们在设计一个功能之前，先把需要设计的功能流程先列出来。这样就知道怎么写代码了。分块一点一点设计。否则没有条理会越写越乱。容易出错。

上面代码其实很简单

第一步：建一个map[string]interface{}

第二步：将前端的发过来的json请求数据获取到，传到&resp map中

第三步：map中现在已经有了数据了，看一下拿到的数据是否正确。

打开网页，登录一下。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/L5De76e110.png?imageslim)

前端发到后端一串json字符串，包括"mobile":"111","password":"111"。

然后我们去后端看一下获取到数据没？

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/cH57fFlKBa.png?imageslim)

已经拿到数据了。然后我们就可以去判断一下拿过来的数据是否合法。

登录验证实现

```go
//2.判断是否合法
if resp["mobile"]==nil || resp["password"]==nil{
   resp["errno"]=models.RECODE_DATAERR
   resp["errmsg"]=models.RecodeText(models.RECODE_DATAERR)
   return
}else if len(resp["mobile"].(string))!=11{
   resp["errno"]=models.RECODE_DATAERR
   resp["errmsg"]=models.RecodeText(models.RECODE_DATAERR)
   return
}
```

我们这个只是简单判断一下是否为空和电话号码长度.

接下来实现到数据库里查询密码是否正确。

```go
//3.与数据库匹配，判断帐号密码是否正确
	o:=orm.NewOrm()
	user:=models.User{Name:resp["mobile"].(string),Password_hash:resp["password"].(string)}

	if err:=o.Read(&user);err!=nil{
		beego.Info("o.Read(&user) err = ",err)
		resp["errno"]=models.RECODE_DATAERR
		resp["errmsg"]=models.RecodeText(models.RECODE_DATAERR)
		return 
	}
	if user.Password_hash!=resp["password"]{
		resp["errno"]=models.RECODE_DATAERR
		resp["errmsg"]=models.RecodeText(models.RECODE_DATAERR)
		return 
	}
```

主要功能

1.先是把获取到的用户名和密码赋值到User结构体中

2.然后从数据库中读取用户名，和密码信息

3.判断一下，如果读取不到，返回给前端错误码

4.判断一下获取到的密码和数据中的密码是否一致

关于上面的查询用户数据还有另外一种方式查询。

```go
//3.与数据库匹配，判断帐号密码是否正确
	o:=orm.NewOrm()
	user:=models.User{Name:resp["mobile"].(string)}
	//查询user表
	qs:=o.QueryTable("user")
	//过滤只查询mobile==user.Name的，One(&user)返回数据到user结构体中，记得用取地址
	err:=qs.Filter("mobile",user.Name).One(&user)
	if err!=nil{
		beego.Info("o.Read(&user) err = ",err)
		resp["errno"]=models.RECODE_DATAERR
		resp["errmsg"]=models.RecodeText(models.RECODE_DATAERR)
		return
	}
	if user.Password_hash!=resp["password"]{
		resp["errno"]=models.RECODE_DATAERR
		resp["errmsg"]=models.RecodeText(models.RECODE_DATAERR)
		return
	}
```



如果登录成功后，我们添加3个 session,用来保持登录状态

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/9mIJ4jAHai.png?imageslim)

```
//4.添加session
this.SetSession("name",resp["mobile"])
this.SetSession("mobile",resp["mobile"])
this.SetSession("user_id",user.Id)
```

最后一步。返回json数据给前端即可。

```
//5.返回json数据给前端
resp["errno"]=models.RECODE_OK
resp["errmsg"]=models.RecodeText(models.RECODE_OK)
```

好了。下面我们来学习一下怎么把城市数据存到缓存模块redis中

## 1.4 redis的使用

### 1.4.1 何为redis

官网： 
<https://redis.io/> 英文版

http://redis.cn/ 中文版

Redis is an in-memory database open-source software project implementing a networked, in-memory key-value store with optional durability. 
Redis是一个开源的、使用C语言编写的、支持网络交互的、可基于内存也可持久化的Key-Value数据库。

**Redis 优势** 
性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。

丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。

原子 – Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。

丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。

**Redis与其他key-value存储有什么不同？** 
Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。

Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。

我们先安装一下redis服务器。我会分别介绍windows和ubuntu两种安装配置方法

### 1.4.2 windows下安装Redis

要安装Redis，首先要获取安装包。

Windows的Redis安装包需要到以下GitHub链接找到。

链接：https://github.com/MSOpenTech/redis

打开网站后，找到Release，点击前往下载页面。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/aHJgba0hB7.png?imageslim)



进入后，我们下载64位系统msi版本

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/CdlgFIb9m2.png?imageslim)



进入安装程序，点下一步

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/chcbgl1dDf.png?imageslim)



接受协议

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/DiagAB3abi.png?imageslim)

选择“添加Redis目录到环境变量PATH中”，这样方便系统自动识别Redis执行文件在哪里。 

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/g7f55dJ4i8.png?imageslim)

端口号可保持默认的6379，并选择防火墙例外，从而保证外部可以正常访问Redis服务。 

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/5ek3JG4Dg7.png?imageslim)

设定最大值为100M。作为实验和学习，100M足够了。 

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/aDICCF41Hb.png?imageslim)

点击安装后，正式的安装过程开始。稍等一会即可完成。 

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/EkBKe7Ecb4.png?imageslim)

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/5m11Bbl6Ad.png?imageslim)

安装完成。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/jGmchjdjd1.png?imageslim)

安装完毕后，需要先做一些设定工作，以便服务启动后能正常运行。

使用文本编辑器，这里使用EmEditor，打开Redis服务配置文件。

文件在C:\Program Files\Redis

注意：不要找错了，通常为redis.windows-service.conf，而不是redis.windows.conf。后者是以非系统服务方式启动程序使用的配置文件。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/33H8L9adGK.png?imageslim)

找到含有requirepass字样的地方（大概在443行），追加一行，输入requirepass 12345。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/LBC54Bh1iI.png?imageslim)

这是访问Redis时所需的密码，一般测试情况下可以不用设定密码。

不过，即使是作为本地访问，也建议设定一个密码。此处以简单的12345来演示。

我这里就不设置密码了。

现在配置一下服务。

在运行中输入services.msc ，打开本地服务，再在右侧找到Redis名称的服务，查看启动情况。如未启动，则手动启动之。正常情况下，服务应该正常启动并运行了。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/H7cJ2kJ6kK.png?imageslim)

最后来测试一下Redis是否正常提供服务。

首先需要重启一下Redis服务，因为我们设置了密码。需要生效

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/3Hhige0cFl.png?imageslim)

进入Redis的目录，cd C:\Program Files\Redis。

输入redis-cli并回车。（redis-cli是客户端程序）

如图正常提示进入，并显示正确端口号，则表示服务已经启动。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/5jLBblCDCJ.png?imageslim)

使用服务前需要先通过密码验证。

输入“auth 12345”并回车（12345是之前设定的密码）。

返回提示OK表示验证通过。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/a7Fd9l5LD4.png?imageslim)

实际测试一下读写。 

格式如下
```
set key value [EX seconds][PX milliseconds] [NX|XX]
```

输入set mykey1 "I love you all!”并回车，用来保存一个键值。

再输入get mykey1，获取刚才保存的键值。

读取没有问题，表明Redis服务安装成功。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/g93CeLE3i0.png?imageslim)

### 1.4.3 linux下安装Redis

环境 Ubuntu 16.04

安装Redis服务器端
```c
$ sudo apt-get install redis-server
```

安装完成后，Redis服务器会自动启动，我们检查Redis服务器程序 

```
$ ps -aux|grep redis
```

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/mi2ELb3AdA.png?imageslim)

通过启动命令检查Redis服务器状态
```
$ netstat -nlt|grep 6379
```

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/A5fg2EG7Ae.png?imageslim)

通过启动命令检查Redis服务器状态

```
$ sudo /etc/init.d/redis-server status
```

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/0i104BK4Ik.png?imageslim)

发现正在运行中。没有问题。

通过命令行客户端访问Redis

安装Redis服务器，会自动地一起安装Redis命令行客户端程序。

在本机输入redis-cli命令就可以启动，客户端程序访问Redis服务器。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/AAADh1gCgD.png?imageslim)

出现端口就没有问题

我们测试一下可不可以读写

//redis-cli -p 6370 p参数可以指定端口

$ redis-cli 
127.0.0.1:6379> set mykey1 "i love you all!"
OK
127.0.0.1:6379> get mykey1
"i love you all!"

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/fKjB0dHmbK.png?imageslim)

```
# 任选数据库(默认有0-15之多)
select 0
# 命令行的帮助
redis 127.0.0.1:6379> help

# 查看所有的key列表
127.0.0.1:6379> KEYS *
1) "mykey1"

# 添加key
127.0.0.1:6379> set mykey1 "i love you all!"
OK

#查看某个key的value
127.0.0.1:6379> get mykey1
"i love you all!"
```

更多的相关redis操作命令在这里查看https://www.cnblogs.com/zongfa/p/7808807.html

配置我们会用上面几个命令就可以了。如果面试问你会用redis吗？可以说会用，但是复杂的查询我们项目中没有用到，我对这方面不太了解。

### 1.4.4 在项目里配置redis

我们现在要实现从redis缓存中拿城区数据。

我觉得有些数据放redis里存比较好，会提升效率，比如说：像淘宝，京东，如果把所有的数据，产品，订单，图片，客户信息都存到mysql数据库中，平时还好。如果遇到双11，618，每天交易量都几百亿，订单数都几千万的。数据库肯定扛不住这么大压力。尤其是双11，0点的时候。瞬间有大量的客户下单。存在关系型数据库中根本不可能，以前肯定要卡死，但是现在不卡了。他肯定是数据先存过一次到redis缓存中，给你一个随机散列cookie值，一但这个用户登录过来之后，根据这个值来去缓存中拿东西。就不走数据库了。

还有一种情况就是，你这段时间访问的是这个页面的内容，过一段时间，网站的内容有些地方就更新成其它的内容了。这个就是mysql更新redis的结果。当mysql统一更新redis数据后，我们再次访问的页面数据也是从redis中取的，所以我们的数据也就跟着更新了。

上面的情况也就限于首页等很少更新的资源才存到redis中。

像内页，比如价格，描述， 产品图片等需要总更新的资源就不可能存到redis中了。肯定是存到关系型数据库中了。我经常要进行update,insert等操作。

一个项目里用到一种数据库是有可能的，但是考虑到性能优化，一般会用两种或多种数据库。

所以我们这个城区的东西放到redis中是最好的了。

我们这个项目如果需要用redis的话，需要安装一些包。下面是安装方法

官方缓存模块说明文档，可以参考一下

https://beego.me/docs/module/cache.md

我们现在把城市区加到缓存模块，这是beego自己集成的，目前beego支持三种缓存模块，file,memcache,memory和redis

我们这次用到的是redis，首先我们来安装一下缓存模块

```
go get github.com/astaxie/beego/cache
```

下载完后会得到如下包

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/0kFEF8FLBB.png?imageslim)

然后如果需要使用memcache或redis的话就需要手工安装引入包 

我们用到的是redis，所以我们去redis官网下载http://redis.cn/

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/FDc3JBd03I.png?imageslim)

打开后点这个客户端。进入

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/fhGD99dAdc.png?imageslim)

会有很多种语言版本，我们选择go版

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/ch3mKacjgg.png?imageslim)

带星标的是最火的，我们选择Redigo

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/Ii2JI7H511.png?imageslim)

点这个图标，分享图标，会进到一个网址github的https://github.com/garyburd/redigo

但是他这个网页不再更新了，而是在另一个目录下更新，下面有提示

Future development of Redigo is at [github.com/gomodule/redigo](https://github.com/gomodule/redigo). Please submit issues at gomodule/redigo. The repository at github.com/garyburd/redigo is a read-only snapshot. 

未来的版本去[github.com/gomodule/redigo](https://github.com/gomodule/redigo)下载。

然后我们去[github.com/gomodule/redigo](https://github.com/gomodule/redigo)，这里会教你怎么安装

按照安装文档上说的，我们去把驱动下载下来

```
go get github.com/gomodule/redigo/redis
```

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/i10chd56lL.png?imageslim)

下载后会得到如下文件

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/dFkbkCIBec.png?imageslim)

下好后，我们去做redis开发集成。

现在我们来导入一下redis包到go项目中，打开controllers/area.go

导入redis包,一共要两个包

```
_ "github.com/astaxie/beego/cache/redis"
"github.com/astaxie/beego/cache"
```

注意。刚才我们下载了两个包是吧。

go get github.com/astaxie/beego/cache

go get github.com/gomodule/redigo/redis

正常情况下需要用到的是github.com/gomodule/redigo/redis这个包

但在这里面不是用这个包，虽然下的是它，但我们用的是"github.com/astaxie/beego/cache/redis"

因为这个包内已经嵌入了github.com/gomodule/redigo/redis包的驱动。所以我们用cache这个redis就可以了。

然后我们不直接操作这个包，我们前面加下划线_ "github.com/astaxie/beego/cache/redis"

尤其是用goland 的时候。如果导入的包不对，就有可能查询不到数据，或提示包不存在的问题，所以这点要注意。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/kCLKD82Lmh.png?imageslim)

我们找到取城区数据这个函数GetArea()

然后初始化一个全局变量对象，

memory是用的哪种数据库，我们改成redis,

`{"interval":60}`，这个参数配置的是引擎，官方介绍了四种引擎

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/C31g5gCmcj.png?imageslim)

我们用redis引擎。把第二个参数替换一下。

```
cache_conn, err := cache.NewCache("redis", `{"key":"lovehome","conn":":6379","dbNum":"0","password":""}`)
```

- key: Redis collection 的名称

  是区分项目中用到了几次redis，比如我们现在写的是lovehome项目，当put数据aa进去的时候，他不会直接写aa，而是将lovehome:aa当成key值put进去，之后才能去用这个东西。之所以出来这样一个东西，是因为人类可用的单词数太少，并且不同的人写的程序不可能所有的变量都没有重名现象，对于库来说，这个问题尤其严重，如果两个人写的库文件中出现同名的变量或函数(不可避免)，使用起来就有问题了。为了解决这个问题，引入了名字空间这个概念，通过使用 namespace xxx；你所使用的库函数或变量就是在该名字空间中定义的，这样一来就不会引起不必要的冲突了。 

- conn: Redis 连接信息，就是端口连接信息,默认是6379

- dbNum: 连接 Redis 时的 DB 编号. 默认是0.就是select 0,选择用哪个数据库

- password: 用于连接有密码的 Redis 服务器.没有密码删除这行就行了

其实我们上面的连接语句和mysql不同而已，但是连上后，操作步骤都一样。

redis常用方法

```go
type Cache interface {
    Get(key string) interface{}
    GetMulti(keys []string) []interface{}
    Put(key string, val interface{}, timeout time.Duration) error
    Delete(key string) error
    Incr(key string) error
    Decr(key string) error
    IsExist(key string) bool
    ClearAll() error
    StartAndGC(config string) error
}
```

timeout time.Duration:代表失效时间，即多久这个key就自动删除了 

我们现在在controllers/area.go里测试一下能不能用go代码操作redis数据

```
//连接redis
cache_conn, err := cache.NewCache("redis", `{"key":"lovehome","conn":":6379","dbNum":"0"}`)
//put一个key:aaa,value:bbb到redis和，失效时间为一小时3600秒
errCache:=cache_conn.Put("aaa","bbb",time.Second*3600)
if errCache!=nil{ //判断错误
   beego.Error("cache err = ",errCache)
}
if err!=nil{//判断错误
   beego.Error("cache_conn err = ",err)
}
//从redis上get信息，返回值是[]byte{}数组bbb为[98,98,98]
beego.Info("cache_conn.aaa = ",cache_conn.Get("aaa"))
```

看一下终端输出信息

2018/06/20 22:25:46.378 [I][area.go:36] cache_conn.aaa =  [98 98 98]

发现打印出来的是二进制输出

我们改一下输出

```
fmt.Printf("cache_conn,aaa = %s\n",cache_conn.Get("aaa"))
```

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/D1ClGKJdi4.png?imageslim)

这样的话就没问题了。

然后我们去看一下redis上有没有数据

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/HGhf0mDIDj.png?imageslim)

发现是有数据的，正常上传上增了

### 1.4.5 防封的golang包下载地址

https://github.com/golang

### 1.4.6 开启redis远程访问

redis服务器默认是处于保护模式并只能本地访问，打开redis.conf文件可以看到如下配置 

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/0G5IBJ3632.png?imageslim)

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/LCf9j1bJ69.png?imageslim)

上两个地方修改后，重新启动redis服务，在远程电脑telnet，可以看到已经通了！ 

$ sudo ps -ef |grep redis |awk '{print $2}' |sudo xargs kill -9

$ redis-server &

$ ps -ef|grep redis

现在我们远程访问一下

redis-cli -h 10.0.151.226 -p 6379 --raw

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/mLilIK5KE4.png?imageslim)

可以访问。

### 1.4.7 redis图形界面客户端使用
redis桌面管理工具 redis-desktop-manager使用指南
一款好用的redis桌面管理工具，支持命令控制台操作，以及常用，查询key，rename，delete等操作。
下载软件，请点击下面链接，进入下载页，选择对应版本：
https://redisdesktop.com/download 
https://www.7down.com/soft/233274.html

先安装，安装就不说，直接下一步就行了。

操作使用如下图

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/gJJ8IEHJG6.png?imageslim)

一、新建连接

输入redis主机host，端口号port，再起个生动形象，简明达意的别名。

 ![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/8fgek708Jf.png?imageslim)

二、该工具支持，add new key(添加新key),reload key(重新载入),filter key(过滤),flush db(删除数据库里面的所有key)

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/h6Be8g6bAB.png?imageslim)

三、针对目标key执行rename，delete，addrow，reload value操作。 

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/dB5i89IIgD.png?imageslim)

四、命令控制台操作

最最最重要的是，该工具提供命令控制台，零距离与redis亲密。知道的小伙伴，都说好，用过的小伙伴都说棒！ 

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/c1HKd6jkdj.png?imageslim)

### 1.4.8 解决redis中文乱码

最近发现存进去的中文字符在windows命令行下显示乱码，用网友提供的解决方法在redis-cli后面加 --raw也不行，linux下就可以解决。所以windows下需要用另外的解决办法

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/030KlgmmAF.png?imageslim)

作为程序员，会经常使用命令窗口查看执行日志，但是有时编码格式不对，大部分都是UTF8，在网上搜索了不少方法，很多没什么用，在这里教一个具体的方法，可以把命令窗口编码方式改为UTF8，接下来按步骤操作 

第一步，打开命令窗口 

下面就是打开的命令窗口，如果我们要修改成UTF8编码，输入命令

CHCP 65001

C:\Users\Administrator>CHCP 65001
Active code page: 65001 提示这行就转成功了

然后再连接远程服务器

C:\Users\Administrator>redis-cli -h 10.0.151.226 -p 6379 --raw

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/3c0H7Bj8J8.png?imageslim)

这样显示就不乱码了。用GUI工具也不乱码。

ubuntu下用--raw参数解决乱码问题

redis-cli --raw

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/FLHa1e1glK.png?imageslim)

## 1.5 地域数据存到redis中 
接下来我们把从数据库中获取到的area数据全部存到redis缓存里面。

先看一下请求地域业务流程。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180620/D6BEJ1emH7.png?imageslim)

正常情况下，前端过来拿数据，先是从redis缓存中拿数据，如果缓存中拿不到数据，就说明没有登录过，就从mysql先把全部数据拿出来，然后打包成json字符串存入到缓存中，然后再把json字符串返回给前端。前端显示地域数据。如果能拿到数据，先把redis数据取出来，然后再解码数据，解码后再次打包成json返回给前端.

当时我们做的是直接从mysql中拿到地域数据，打包成json数据，然后返回给前端。

现在我们添加代码，在从数据库取数据之前添加一段代码。先从缓存中取，如果取不到，再从数据库中取。

```go
beego.Info("connect success")
resp:=make(map[string]interface{})

//每次return都会执行一次这行返回json数据
defer c.RetData(resp)
//从redis拿数据,连接redis服务器
cache_conn, err := cache.NewCache("redis", `{"key":"lovehome","conn":":6379","dbNum":"0"}`)

if err!=nil{
   beego.Error("cache_conn err = ",err)
   resp["errno"]=models.RECODE_DATAERR
   resp["errmsg"]=models.RecodeText(models.RECODE_DATAERR)
   return
}
areaData:=cache_conn.Get("area")
if areaData!=nil{
   beego.Info("get data from cache=============")
   //查询成功返回数据
   resp["errno"]=models.RECODE_OK
   resp["errmsg"]=models.RecodeText(models.RECODE_OK)
   //把从redis中取来的数据必须先解码才能在前台显示。
   var areas_info interface{}
   //解码数据并存到areas_info中
   json.Unmarshal(areaData.([]byte),&areas_info)
   resp["data"]=areas_info
   return
}
```

上面的代码请注意，从redis中拿到的数据，一定要json.Unmarshal解码一次，否则前端显示不出来。

上面代码流程如下：
```
1.连接redis服务器
cache_conn, err := cache.NewCache("redis", `{"key":"lovehome","conn":":6379","dbNum":"0"}`)
2.取数据
areaData:=cache_conn.Get("area")
3.把数据解码
var areas_info interface{}
//解码数据并存到areas_info中
json.Unmarshal(areaData.([]byte),&areas_info)
4.将解码后听数据传给resp["data"]
resp["data"]=areas_info
5.打包成json返回给前端
```

下面三行代码很重要，注意。我就在这遇到了坑。调试了好长时间

```go
//把从redis中取来的数据必须先解码才能在前台显示。
var areas_info interface{}
//解码数据并存到areas_info中
json.Unmarshal(areaData.([]byte),&areas_info)
resp["data"]=areas_info
```

下面是从如果缓存中没数据，从数据库中查询数据并存到redis中。

```go
//第一步，从数据库中拿到数据。
//声明一个数组用来存从数据库中查询到的所有城区数据。用数组
o:=orm.NewOrm()
var areas []models.Area

//查询area表里的全部数据，存到areas缓存数组中，返回的是int64查询的条数，error错误信息
num,err:=o.QueryTable("area").All(&areas)
//如果没查询到返回的数据
if err!=nil{
   resp["errno"]=models.RECODE_DBERR
   resp["errmsg"]=models.RecodeText(models.RECODE_DBERR)
   return
}
if num==0{
   resp["errno"]=models.RECODE_NODATA
   resp["errmsg"]=models.RecodeText(models.RECODE_NODATA)
   return
}

resp["data"]=areas //把上面查询到的数据传给data

//把取到的数据转换成json格式存入缓存
json_str,err:=json.Marshal(areas)
if err!=nil{
   resp["errno"]=models.RECODE_DBERR
   resp["errmsg"]=models.RecodeText(models.RECODE_DBERR)
   return
}
json_err:=cache_conn.Put("area",json_str,time.Second*3600)
if json_err!=nil{
   resp["errno"]=models.RECODE_DBERR
   resp["errmsg"]=models.RecodeText(models.RECODE_DBERR)
   return
}
//查询成功返回数据
resp["errno"]=models.RECODE_OK
resp["errmsg"]=models.RecodeText(models.RECODE_OK)
```
```
数据库操作流程：

1.定义一个存数据的结构体数组

var areas []models.Area

2.从数据库中把数据读出来存到结构体数组中

num,err:=o.QueryTable("area").All(&areas)

3.把存好的数据存到resp["data"]中，打包json时候要用

resp["data"]=areas

4.把读取到的先转成json字符串

json_str,err:=json.Marshal(areas)

5.然后把json字符串存到redis缓存中

json_err:=cache_conn.Put("area",json_str,time.Second*3600)

6.查询成功，返回成功错误码

resp["errno"]=models.RECODE_OK
resp["errmsg"]=models.RecodeText(models.RECODE_OK)

7.将错误码和resp["data"]一起打包成json字符串返回给前端

defer c.RetData(resp)
```

以下是area.go完整代码

```go
package controllers

import (
   "github.com/astaxie/beego"
   "loveHome/models"
   "github.com/astaxie/beego/orm"
   _ "github.com/astaxie/beego/cache/redis"
   "github.com/astaxie/beego/cache"
   "encoding/json"
   "time"
)

type AreaController struct {
   beego.Controller
}

func (this *AreaController) RetData(resp map[string]interface{})  {
   this.Data["json"] = resp
   this.ServeJSON()
}

func (c *AreaController) GetArea() {
   beego.Info("connect success")
   resp:=make(map[string]interface{})

   //每次return都会执行一次这行返回json数据
   defer c.RetData(resp)
   //从redis拿数据
   cache_conn, err := cache.NewCache("redis", `{"key":"lovehome","conn":":6379","dbNum":"0"}`)

   if err!=nil{
      beego.Error("cache_conn err = ",err)
      resp["errno"]=models.RECODE_DATAERR
      resp["errmsg"]=models.RecodeText(models.RECODE_DATAERR)
      return
   }
   areaData:=cache_conn.Get("area")
   if areaData!=nil{
      beego.Info("get data from cache=============")
      //查询成功返回数据
      resp["errno"]=models.RECODE_OK
      resp["errmsg"]=models.RecodeText(models.RECODE_OK)
      //把从redis中取来的数据必须先解码才能在前台显示。
      var areas_info interface{}
      //解码数据并存到areas_info中
      json.Unmarshal(areaData.([]byte),&areas_info)
      resp["data"]=areas_info
      return
   }

   //第一步，从数据库中拿到数据。
   //声明一个数组用来存从数据库中查询到的所有城区数据。用数组
   o:=orm.NewOrm()
   var areas []models.Area

   //查询area表里的全部数据，存到areas缓存数组中，返回的是int64查询的条数，error错误信息
   num,err:=o.QueryTable("area").All(&areas)
   //如果没查询到返回的数据
   if err!=nil{
      resp["errno"]=models.RECODE_DBERR
      resp["errmsg"]=models.RecodeText(models.RECODE_DBERR)
      return
   }
   if num==0{
      resp["errno"]=models.RECODE_NODATA
      resp["errmsg"]=models.RecodeText(models.RECODE_NODATA)
      return
   }

   resp["data"]=areas //把上面查询到的数据传给data

   //把取到的数据转换成json格式存入缓存
   json_str,err:=json.Marshal(areas)
   if err!=nil{
      resp["errno"]=models.RECODE_DBERR
      resp["errmsg"]=models.RecodeText(models.RECODE_DBERR)
      return
   }
   json_err:=cache_conn.Put("area",json_str,time.Second*3600)
   if json_err!=nil{
      resp["errno"]=models.RECODE_DBERR
      resp["errmsg"]=models.RecodeText(models.RECODE_DBERR)
      return
   }
   //查询成功返回数据
   resp["errno"]=models.RECODE_OK
   resp["errmsg"]=models.RecodeText(models.RECODE_OK)
   //第二步，把拿到的数据打包成json返回给前端。
   //上面已经defer c.RetData(resp)了，所以就不用写了
   beego.Info("query data succee ,resp = ",resp,"num = ",num)

}
```

## 1.6 fastdfs环境配置

FastDFS 是一个开源的高性能分布式文件系统（DFS）。 它的主要功能包括：文件存储，文件同步和文件访问，以及高容量和负载平衡。主要解决了海量数据存储问题，特别适合以中小文件（建议范围：4KB < file_size <500MB）为载体的在线服务。例如图片分享和视频分享网站 

FastDFS 系统有三个角色：跟踪服务器(Tracker Server)、存储服务器(Storage Server)和客户端(Client)。

跟踪和存储服务可以由1台或者多台服务器组成 ，同时可以对服务动态的添加，删除，存储，而不会对现有服务集群有影响。

**Tracker Server**：跟踪服务器，主要做调度工作，起到均衡的作用；负责管理所有的 storage server和 group，每个 storage 在启动后会连接 Tracker，告知自己所属 group 等信息，并保持周期性心跳。

跟踪服务器（Tracker Server）可以由1个或多个卷组成。每个卷之间都是相互独立的，所有卷的文件容量累加就是整个存储系统中的文件容量。 

**Storage Server**：存储服务器，主要提供容量和备份服务；以 group 为单位，每个 group 内可以有多台 storage server，数据互为备份。

一个卷跟踪服务器（Tracker Server）可以由一台或多台存储服务器（Storage Server）组成，一个卷下的存储服务器中的文件都是相同的， 卷中的多台存储服务器起到了冗余备份和负载均衡的作用。 如果在卷中增加存储服务器时，系统会自动同步数据到这台新存储服务器上。同步完成后，系统会自动把新存储服务器切换到线上提供服务，当存储空间不足或即将耗尽时，可以动态添加卷。只需要增加一台或多台服务器，并将它们配置为一个新的卷，这样就扩大了存储系统的容量。 

**Client**：客户端，上传下载数据的服务器，也就是我们自己的项目所部署在的服务器。

现在我们开始部署一下fastdfs服务器。

这货在windows下没有，只有linux版

我们开一台虚拟机，系统为ubuntu16.04 x64,以下操作都是单机环境。

先提升权限到root

```
$ su -
```

先做一件事，修改hosts，将文件服务器的ip与域名映射(单机TrackerServer环境)，因为后面很多配置里面都需要去配置服务器地址，ip变了，就只需要修改hosts即可。

```
# vim /etc/hosts

增加如下一行，这是我的IP
10.0.151.220 file.fastdfs.com

如果要本机访问虚拟机，在C:\Windows\System32\drivers\etc\hosts中同样增加一行
```

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/I1hABK279c.png?imageslim)

ping一下测试，返回ip正确

```
root@ubuntu:/etc/fdfs# ping file.fastdfs.com
PING file.fastdfs.com (10.0.151.220) 56(84) bytes of data.
64 bytes from file.fastdfs.com (10.0.151.220): icmp_seq=1 ttl=64 time=0.025 ms
64 bytes from file.fastdfs.com (10.0.151.220): icmp_seq=2 ttl=64 time=0.050 ms

```

### 1、下载安装 libfastcommon

libfastcommon是从 FastDFS 和 FastDHT 中提取出来的公共 C 函数库，基础环境，安装即可 。

① 下载libfastcommon

```
# wget https://github.com/happyfish100/libfastcommon/archive/V1.0.7.tar.gz
```

② 解压

```
# tar -zxvf V1.0.7.tar.gz
# cd libfastcommon-1.0.7
```

③ 编译、安装

```
# ./make.sh
# ./make.sh install
```

④ libfastcommon.so 安装到了/usr/lib64/libfastcommon.so，但是FastDFS主程序设置的lib目录是/usr/local/lib，所以需要创建软链接。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/imAc4ahCcF.png?imageslim)

```
# ln -s /usr/lib64/libfastcommon.so /usr/local/lib/libfastcommon.so
# ln -s /usr/lib64/libfastcommon.so /usr/lib/libfastcommon.so
# ln -s /usr/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.so
# ln -s /usr/lib64/libfdfsclient.so /usr/lib/libfdfsclient.so
```
### 2、下载安装FastDFS

① 下载FastDFS

```
# wget https://github.com/happyfish100/fastdfs/archive/V5.05.tar.gz
```

② 解压

```
# tar -zxvf V5.05.tar.gz
# cd fastdfs-5.05
```

③ 编译、安装

```
# ./make.sh
# ./make.sh install
```

④ 默认安装方式安装后的相应文件与目录
　　A、服务脚本：

```
/etc/init.d/fdfs_storaged
/etc/init.d/fdfs_tracker
```

　　B、配置文件（这三个是作者给的样例配置文件） :

```
/etc/fdfs/client.conf.sample
/etc/fdfs/storage.conf.sample
/etc/fdfs/tracker.conf.sample
```

　　C、命令工具在 /usr/bin/ 目录下：

```
fdfs_appender_test
fdfs_appender_test1
fdfs_append_file
fdfs_crc32
fdfs_delete_file
fdfs_download_file
fdfs_file_info
fdfs_monitor
fdfs_storaged
fdfs_test
fdfs_test1
fdfs_trackerd
fdfs_upload_appender
fdfs_upload_file
stop.sh
restart.sh 
```

⑤ FastDFS 服务脚本设置的 bin 目录是 /usr/local/bin， 但实际命令安装在 /usr/bin/ 下。 

两种方式：

　　一是修改FastDFS 服务脚本中相应的命令路径，也就是把 /etc/init.d/fdfs_storaged 和 /etc/init.d/fdfs_tracker 两个脚本中的 /usr/local/bin 修改成 /usr/bin。
```
vim fdfs_trackerd
使用查找替换命令进统一修改:%s+/usr/local/bin+/usr/bin
vim fdfs_storaged
使用查找替换命令进统一修改:%s+/usr/local/bin+/usr/bin
```
![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/hAkl8hBiJ3.png?imageslim)

　　二是建立 /usr/bin 到 /usr/local/bin 的软链接，我是用这种方式。　　

```
# ln -s /usr/bin/fdfs_trackerd   /usr/local/bin
# ln -s /usr/bin/fdfs_storaged   /usr/local/bin
# ln -s /usr/bin/stop.sh         /usr/local/bin
# ln -s /usr/bin/restart.sh      /usr/local/bin
```
![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/cIicI0cHKI.png?imageslim)

### 3、配置FastDFS跟踪器(Tracker)

配置文件详细说明参考：

http://bbs.chinaunix.net/forum.php?mod=viewthread&tid=1941456&extra=page%3D1%26filter%3Ddigest%26digest%3D1

① 进入 /etc/fdfs，复制 FastDFS 跟踪器样例配置文件 tracker.conf.sample，并重命名为 tracker.conf。

```
# cd /etc/fdfs
# cp tracker.conf.sample tracker.conf
# vim tracker.conf
```

② 编辑tracker.conf ，标红的需要修改下，其它的默认即可。

```
# 配置文件是否不生效，false 为生效
disabled=false

# 提供服务的端口
port=22122

# Tracker 数据和日志目录地址(根目录必须存在,子目录会自动创建)
base_path=/home/fastdfs/tracker

# HTTP 服务端口
http.server_port=9998
```

③ 创建tracker基础数据目录，即base_path对应的目录

```
# mkdir -p /home/fastdfs/tracker
```

④ 防火墙中打开跟踪端口（默认的22122）,一般把防火墙关了就不用配置了。我已经关了

防火墙方法只支持centos

```
# vim /etc/sysconfig/iptables

添加如下端口行：
-A INPUT -m state --state NEW -m tcp -p tcp --dport 22122 -j ACCEPT

重启防火墙：
# service iptables restart
```

⑤ 启动Tracker

初次成功启动，会在 /home/fastdfs/tracker/ (配置的base_path)下创建 data、logs 两个目录。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/aGACKmm0jF.png?imageslim)

```
ubuntu可以用这种方式启动,后面都用这种启动
# /etc/init.d/fdfs_trackerd start
报错：/etc/init.d/fdfs_trackerd: line 13: /etc/init.d/functions: No such file or directory
以上报错可以忽略

centos也可以用这种方式启动，前提是上面创建了软链接，这个方式只支持centos
# service fdfs_trackerd start
报错：Failed to start fdfs_trackerd.service: Unit fdfs_trackerd.service not found.

```

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/il6mdK5Fa1.png?imageslim)

查看 FastDFS Tracker 是否已成功启动 ，22122端口正在被监听，则算是Tracker服务安装成功。

```
# netstat -unltp|grep fdfs
```

![img](https://images2017.cnblogs.com/blog/856154/201710/856154-20171011121344184-1089101646.png)

关闭Tracker命令：

```
ubuntu方式
# /etc/init.d/fdfs_trackerd stop
centos方式
# service fdfs_trackerd stop
```

⑥ 设置Tracker开机启动

```
centos方式
# chkconfig fdfs_trackerd on

或者：
ubuntu方式
# vim /etc/rc.local
加入配置：
/etc/init.d/fdfs_trackerd start 
保存，这样每次开机就自动启动
```

⑦ tracker server 目录及文件结构 

Tracker服务启动成功后，会在base_path下创建data、logs两个目录。目录结构如下：

```
root@ubuntu:/home/fastdfs/tracker# tree
.
├── data
│   ├── fdfs_trackerd.pid
│   ├── storage_changelog.dat
│   ├── storage_groups_new.dat 存储分组信息
│   ├── storage_servers_new.dat 存储服务器列表
│   └── storage_sync_timestamp.dat
└── logs
    └── trackerd.log 日志文件

2 directories, 6 files
```
### 4、配置FastDFS存储 (Storage)

① 进入 /etc/fdfs 目录，复制 FastDFS 存储器样例配置文件 storage.conf.sample，并重命名为 storage.conf

```
# cd /etc/fdfs
# cp storage.conf.sample storage.conf
# vim storage.conf
```

② 编辑storage.conf

标红的需要修改，其它的默认即可。

```
# 配置文件是否不生效，false 为生效
disabled=false 

# 指定此 storage server 所在 组(卷)
group_name=group1

# storage server 服务端口
port=23000

# 心跳间隔时间，单位为秒 (这里是指主动向 tracker server 发送心跳)
heart_beat_interval=30

# Storage 数据和日志目录地址(根目录必须存在，子目录会自动生成)
base_path=/home/fastdfs/storage

# 存放文件时 storage server 支持多个路径。这里配置存放文件的基路径数目，通常只配一个目录。
store_path_count=1


# 逐一配置 store_path_count 个路径，索引号基于 0。
# 如果不配置 store_path0，那它就和 base_path 对应的路径一样。
store_path0=/home/fastdfs/file

# FastDFS 存储文件时，采用了两级目录。这里配置存放文件的目录个数。 
# 如果本参数只为 N（如： 256），那么 storage server 在初次运行时，会在 store_path 下自动创建 N * N 个存放文件的子目录。
subdir_count_per_path=256

# tracker_server 的列表 ，会主动连接 tracker_server
# 有多个 tracker server 时，每个 tracker server 写一行
# 我的是单机，所以用的本机ip，10.0.151.220，刚才我们已经做了hosts映射，所以直接用域名就可以了
# ip不能用127.0.0.1和localhost,否则启动不了
tracker_server=file.fastdfs.com:22122

# 允许系统同步的时间段 (默认是全天) 。一般用于避免高峰同步产生一些问题而设定。
sync_start_time=00:00
sync_end_time=23:59
# 访问端口
http.server_port=9998
```

③ 创建Storage基础数据目录，对应base_path目录

```
# mkdir -p /home/fastdfs/storage

# 这是配置的store_path0路径
# mkdir -p /home/fastdfs/file
```

④ 防火墙中打开存储器端口（默认的 23000） ,只针对centos.ubuntu把防火墙关了就行

```
# vim /etc/sysconfig/iptables

添加如下端口行：
-A INPUT -m state --state NEW -m tcp -p tcp --dport 23000 -j ACCEPT

重启防火墙：
# service iptables restart
```

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/6829fG9h0l.png?imageslim)

⑤ 启动 Storage

启动Storage前确保Tracker是启动的。初次启动成功，会在 /home/fastdfs/storage 目录下创建 data、 logs 两个目录。

```
ubuntu可以用这种方式启动，后面都用这种方式启动
# /etc/init.d/fdfs_storaged start
/etc/init.d/fdfs_storaged: line 13: /etc/init.d/functions: No such file or directory
Starting FastDFS storage server: 
上面的错误，可以忽略

centos可以用这种方式
# service fdfs_storaged start
```

查看 Storage 是否成功启动，23000 端口正在被监听，就算 Storage 启动成功。

```
# netstat -unltp|grep fdfs
```

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/35JedHKfhk.png?imageslim)

发现没启动成功。没有23000端口，去看日志/home/fastdfs/storage/logs

root@ubuntu:/home/fastdfs/storage/logs# cat storaged.log 
[2018-06-21 16:47:41] ERROR - file: storage_func.c, line: 1183, conf file "/etc/fdfs/storage.conf", tracker: "127.0.0.1:22122" is invalid, tracker server ip can't be 127.0.0.1
[2018-06-21 16:47:41] CRIT - exit abnormally!

服务器说不让用127.0.0.1连接tracker server ip,换一下。发现只有改成10.0.151.220或者域名file.fastdfs.com才可以启动服务。

改成127.0.0.1和localhost都不让启动

已经启动成功了

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/AdfDK0BFck.png?imageslim)

关闭Storage命令：

```
ubuntu可以用这种方式启动，后面都用这种方式启动
# /etc/init.d/fdfs_storaged stop

centos用这种
# service fdfs_storaged stop
```

查看Storage和Tracker是否在通信：

```
/usr/bin/fdfs_monitor /etc/fdfs/storage.conf
```

ACTIVE就说明已经可以正常通信

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/HfkiIgiH2F.png?imageslim)

⑥ 设置 Storage 开机启动


```
centos用这种
# chkconfig fdfs_storaged on

ubuntu用这种
# vim /etc/rc.local
加入配置：
/etc/init.d/fdfs_storaged start
```

⑦ Storage 目录

同 Tracker，Storage 启动成功后，在base_path 下创建了data、logs目录，记录着 Storage Server 的信息。

在 store_path0 目录下，创建了N*N个子目录：

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/6lELdKc87f.png?imageslim)

### 5、文件上传测试

① 修改 Tracker 服务器中的客户端配置文件 

```
# cd /etc/fdfs
# cp client.conf.sample client.conf
# vim client.conf
```

修改如下配置即可，其它默认。

```
# Client 的数据和日志目录
base_path=/home/fastdfs/client

# Tracker端口，这里我直接用域名了
tracker_server=file.fastdfs.com:22122
```

② 上传测试

 在linux内部执行如下命令上传 namei.jpeg 图片

```
#  /usr/bin/fdfs_upload_file /etc/fdfs/client.conf 1.jpg
```

报错：[2018-06-21 17:28:45] ERROR - file: ../client/client_func.c, line: 257, "/home/fastdfs/client" can't be accessed, error info: No such file or directory

原因是没创建/home/fastdfs/client目录

```
# mkdir -p /home/fastdfs/client
```
上传测试成功。已经成功将数据上传到服务器中

```
# /usr/bin/fdfs_upload_file /etc/fdfs/client.conf /root/1.jpg 
group1/M00/00/00/CgCX3FsrfyOABuA2AAFqdROOF2Y596.jpg
```


上传成功后返回文件ID号：group1/M00/00/00/CgCX3FsrfyOABuA2AAFqdROOF2Y596.jpg

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/F64CmcKfI3.png?imageslim)

去这个目录下可以找到刚才上传的文件

cd /home/fastdfs/file/data/00/00

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/BG8ge93m1C.png?imageslim)

返回的文件ID由group、存储目录、两级子目录、fileid、文件后缀名（由客户端指定，主要用于区分文件类型）拼接而成。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/7h9cbdElhe.png?imageslim)

### 6、安装Nginx

上面将文件上传成功了，但我们无法下载。因此安装Nginx作为服务器以支持Http方式访问文件。同时，后面安装FastDFS的Nginx模块也需要Nginx环境。

Nginx只需要安装到StorageServer所在的服务器即可，用于访问文件。我这里由于是单机，TrackerServer和StorageServer在一台服务器上。

安装前环境准备

安装gcc g++的依赖库

```
sudo apt-get install build-essential
sudo apt-get install libtool
```

安装pcre依赖库（<http://www.pcre.org/>）

```
sudo apt-get update
sudo apt-get install libpcre3 libpcre3-dev
```

安装zlib依赖库（[http://www.zlib.net](http://www.zlib.net/)）

```
sudo apt-get install zlib1g-dev
```

安装SSL依赖库（16.04默认已经安装了）

```
sudo apt-get install openssl
```

① 下载nginx

```
#下载最新版本：
wget http://nginx.org/download/nginx-1.13.6.tar.gz
```

② 解压

```
#解压：
tar -zxvf nginx-1.13.6.tar.gz
#进入解压目录：
cd nginx-1.13.6
```

③ 配置

```
#配置：
./configure --prefix=/usr/local/nginx 
```

④ 编译、安装

```
# make
# make install
```

⑤ 启动nginx

```
# cd /usr/local/nginx/sbin/
# /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf
注意：-c 指定配置文件的路径，不加的话，nginx会自动加载默认路径的配置文件，可以通过-h查看帮助命令。

其它命令
# ./nginx -s stop
# ./nginx -s quit
# ./nginx -s reload

#查看进程：
ps -ef | grep nginx
```

⑥ 设置开机启动

```
# vim /etc/rc.local

添加一行：
/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf

# 设置执行权限
# chmod 755 rc.local
```

⑦ 查看nginx的版本及模块

```
/usr/local/nginx/sbin/nginx -V
```

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/BmDDc6C6f9.png?imageslim)

⑧ 防火墙中打开Nginx端口（默认的 80） 如果改了端口，防火墙规则就开放此端口

添加后就能在本机使用80端口访问了。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/CaAla26b3E.png?imageslim)

### 7、设置nginx访问可以文件fdfs文件目录

简单的测试访问文件

① 修改nginx.conf

```
# vim /usr/local/nginx/conf/nginx.conf

在server {}最后一行添加如下行
将 /group1/M00 映射到 /ljzsg/fastdfs/file/data
location /group1/M00 {
    alias /home/fastdfs/file/data;
}

# 重启nginx
# /usr/local/nginx/sbin/nginx -s reload
```

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/ALi2919D5d.png?imageslim)

② 在浏览器访问之前上传的图片、成功。

http://10.0.151.220/group1/M00/00/00/CgCX3FsrfyOABuA2AAFqdROOF2Y596.jpg

### 8、FastDFS 配置 Nginx 模块

① fastdfs-nginx-module 模块说明

　　FastDFS 通过 Tracker 服务器，将文件放在 Storage 服务器存储， 但是同组存储服务器之间需要进行文件复制， 有同步延迟的问题。

　　假设 Tracker 服务器将文件上传到了 192.168.51.128，上传成功后文件 ID已经返回给客户端。

　　此时 FastDFS 存储集群机制会将这个文件同步到同组存储 192.168.51.129，在文件还没有复制完成的情况下，客户端如果用这个文件 ID 在 192.168.51.129 上取文件,就会出现文件无法访问的错误。

　　而 fastdfs-nginx-module 可以重定向文件链接到源服务器取文件，避免客户端由于复制延迟导致的文件无法访问错误。

② 下载 fastdfs-nginx-module、解压

```
# 这里为啥这么长一串呢，因为最新版的master与当前nginx有些版本问题。
# wget https://github.com/happyfish100/fastdfs-nginx-module/archive/5e5f3566bbfa57418b5506aaefbe107a42c9fcb1.zip

# 解压没装unzip需要安装apt install unzip
# unzip 5e5f3566bbfa57418b5506aaefbe107a42c9fcb1.zip

# 重命名
# mv fastdfs-nginx-module-5e5f3566bbfa57418b5506aaefbe107a42c9fcb1  fastdfs-nginx-module-master
```

③ 配置Nginx

在nginx中添加模块

```
# 先停掉nginx服务
# /usr/local/nginx/sbin/nginx -s stop

进入解压包目录
# cd /root/nginx-1.13.6/

# 添加模块
# ./configure --add-module=../fastdfs-nginx-module-master/src

重新编译、安装
# make && make install
```

 ④ 查看Nginx的fastdfs模块

```
# /usr/local/nginx/sbin/nginx -V
```

有下面这个就说明添加模块成功

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/Ja518DG94e.png?imageslim)

⑤ 复制 fastdfs-nginx-module 源码中的配置文件到/etc/fdfs 目录， 并修改

```
# cd /root/fastdfs-nginx-module-master/src
# cp mod_fastdfs.conf /etc/fdfs/
# cd /etc/fdfs/
# vim mod_fastdfs.conf
```

修改如下配置，其它默认

```
# 连接超时时间
connect_timeout=10

# Tracker Server
tracker_server=file.fastdfs.com:22122

# StorageServer 默认端口
storage_server_port=23000

# 如果文件ID的uri中包含/group**，则要设置为true
url_have_group_name = true

# Storage 配置的store_path0路径，必须和storage.conf中的一致
store_path0=/home/fastdfs/file
```

⑥ 复制 FastDFS 的部分配置文件到/etc/fdfs 目录

```
# cd /root/fastdfs-5.05/conf/

# cp anti-steal.jpg http.conf mime.types /etc/fdfs/
```

 ⑦ 配置nginx，修改nginx.conf

```
# vim /usr/local/nginx/conf/nginx.conf
```

修改配置，其它的默认

在server{}最后一行添加fastdfs-nginx模块

```
location ~/group([0-9])/M00 {
    ngx_fastdfs_module;
}
```

原来配置的group1就可以注释掉了

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/7J4g9I37iG.png?imageslim)

注意：

　　listen 80 端口值是要与 /etc/fdfs/storage.conf 中的 http.server_port=80 (前面改成80了)相对应。如果改成其它端口，则需要统一，同时在防火墙中打开该端口。

　　location 的配置，如果有多个group则配置location ~/group([0-9])/M00 ，没有则不用配group。

⑧ 在/home/fastdfs/file 文件存储目录下创建软连接，将其链接到实际存放数据的目录，这一步可以省略。

```
# ln -s /home/fastdfs/file/data/ /home/fastdfs/file/data/M00 
```

⑨ 启动nginx

```
# /usr/local/nginx/sbin/nginx
```

打印处如下就算配置成功

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/hC7Hf6bLiJ.png?imageslim)

⑩ 在地址栏访问。

能下载文件就算安装成功。注意和第三点中直接使用nginx路由访问不同的是，这里配置 fastdfs-nginx-module 模块，可以重定向文件链接到源服务器取文件。

http://10.0.151.220:9998/group1/M00/00/00/CgCX3FsrfyOABuA2AAFqdROOF2Y596.jpg

完美取到文件。

![1529585844245](C:\Users\Administrator\AppData\Local\Temp\1529585844245.png)

最终部署结构图(盗的图)：可以按照下面的结构搭建环境。 

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/1d85K1H6HL.png?imageslim)

### 9、权限控制

因为是测试项目，权限我们就限制了。怕引起不必要的坑。以后项目正式上线后再设置

前面使用nginx支持http方式访问文件，但所有人都能直接访问这个文件服务器了，所以做一下权限控制。

FastDFS的权限控制是在服务端开启token验证，客户端根据文件名、当前unix时间戳、秘钥获取token，在地址中带上token参数即可通过http方式访问文件。

① 服务端开启token验证

```
修改http.conf
# vim /etc/fdfs/http.conf

设置为true表示开启token验证
http.anti_steal.check_token=true

设置token失效的时间单位为秒(s)
http.anti_steal.token_ttl=1800

密钥，跟客户端配置文件的fastdfs.http_secret_key保持一致
http.anti_steal.secret_key=FASTDFS1234567890

如果token检查失败，返回的页面
http.anti_steal.token_check_fail=/ljzsg/fastdfs/page/403.html
```

记得重启服务。

② 配置客户端

客户端只需要设置如下两个参数即可，两边的密钥保持一致。

```
# token 防盗链功能
fastdfs.http_anti_steal_token=true
# 密钥
fastdfs.http_secret_key=FASTDFS1234567890
```

③ 客户端生成token

访问文件需要带上生成的token以及unix时间戳，所以返回的token是token和时间戳的拼接。

之后，将token拼接在地址后即可访问：

http://10.0.151.220:9998/group1/M00/00/00/CgCX3FsrfyOABuA2AAFqdROOF2Y596.jpg?token=078d370098b03e9020b82c829c205e1f&ts=1508141521

```java
     /**
      * 获取访问服务器的token，拼接到地址后面
      *
      * @param filepath 文件路径 group1/M00/00/00/wKgzgFnkTPyAIAUGAAEoRmXZPp876.jpeg
      * @param httpSecretKey 密钥
      * @return 返回token，如： token=078d370098b03e9020b82c829c205e1f&ts=1508141521
      */
public static String getToken(String filepath, String httpSecretKey){
         // unix seconds
         int ts = (int) Instant.now().getEpochSecond();
         // token
         String token = "null";
         try {
             token = ProtoCommon.getToken(getFilename(filepath), ts, httpSecretKey);
         } catch (UnsupportedEncodingException e) {
             e.printStackTrace();
         } catch (NoSuchAlgorithmException e) {
             e.printStackTrace();
         } catch (MyException e) {
             e.printStackTrace();
         }
 
         StringBuilder sb = new StringBuilder();
         sb.append("token=").append(token);
         sb.append("&ts=").append(ts);
 
        return sb.toString();
}
```

④ 注意事项

如果生成的token验证无法通过，请进行如下两项检查：
　　A. 确认调用token生成函数(ProtoCommon.getToken)，传递的文件ID中没有包含group name。传递的文件ID格式形如：M00/00/00/wKgzgFnkTPyAIAUGAAEoRmXZPp876.jpeg

　　B. 确认服务器时间基本是一致的，注意服务器时间不能相差太多，不要相差到分钟级别。

⑤ 对比下发现，如果系统文件隐私性较高，可以直接通过fastdfs-client提供的API去访问即可，不用再配置Nginx走http访问。配置Nginx的主要目的是为了快速访问服务器的文件(如图片)，如果还要加权限验证，则需要客户端生成token，其实已经没有多大意义。

## 1.7 项目中fastdfs文件上传大概实现步骤

我们刚才把fastdfs环境搭建起来了。然后通过网页已经能访问到上传的文件。我们看一下我们的上传文件路径。

/home/fastdfs/file/data/00/00，我们上传的文件一般在这个目录下面。

看一下网站访问的目录。

http://10.0.151.220:9998/group1/M00/00/00/CgCX3FsrfyOABuA2AAFqdROOF2Y596.jpg

在这里。我现在想实现访问我们的项目网站，然后能在网站上调用我们的fastdfs里的图片。

但是beego里给提供了一个重定向函数。

```
beego.SetStaticPath("group1/M00/","/home/fastdfs/file/data/")
```

但是我是在另外一台虚拟机上安装的fastdfs服务，所以不能这么用。

## 1.8 fdfs集成

我们已经搭建好了。fdfs，我们一般上传文件用命令行fdfs_upload_file上传

但是如果我们用go上传的话需要用go语言的接口实现上传功能。

我们去github上可以找到有雷锋写好的go语言接口

进到github上搜索fdfs，找到一个叫weilaihui写的fdfs_client接口，用的人也挺多的。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/9dKC0FdJhd.png?imageslim)

我们就用这个接口上传。

把接口下载下来。

$ go get github.com/weilaihui/fdfs_client 

安装完后我们看他有个示例代码可以学习的。

https://github.com/weilaihui/fdfs_client/blob/master/client_test.go

常用的方法都在这里写好了。有两个函数。

```go
通过文件上传
func TestUploadByFilename(t *testing.T) {
   fdfsClient, err := NewFdfsClient("client.conf")
   if err != nil {
      t.Errorf("New FdfsClient error %s", err.Error())
      return
   }

   uploadResponse, err = fdfsClient.UploadByFilename("client.conf")
   if err != nil {
      t.Errorf("UploadByfilename error %s", err.Error())
   }
   t.Log(uploadResponse.GroupName)
   t.Log(uploadResponse.RemoteFileId)
   fdfsClient.DeleteFile(uploadResponse.RemoteFileId)
}

通过数组上传
func TestUploadByBuffer(t *testing.T) {
   fdfsClient, err := NewFdfsClient("client.conf")
   if err != nil {
      t.Errorf("New FdfsClient error %s", err.Error())
      return
   }

   file, err := os.Open("testfile") // For read access.
   if err != nil {
      t.Fatal(err)
   }

   var fileSize int64 = 0
   if fileInfo, err := file.Stat(); err == nil {
      fileSize = fileInfo.Size()
   }
   fileBuffer := make([]byte, fileSize)
   _, err = file.Read(fileBuffer)
   if err != nil {
      t.Fatal(err)
   }

   uploadResponse, err = fdfsClient.UploadByBuffer(fileBuffer, "txt")
   if err != nil {
      t.Errorf("TestUploadByBuffer error %s", err.Error())
   }

   t.Log(uploadResponse.GroupName)
   t.Log(uploadResponse.RemoteFileId)
   fdfsClient.DeleteFile(uploadResponse.RemoteFileId)
}
```

现在我们就用这个工具实现图片上传。

先在models目录下创建fdfs.go

```go
package models

//导入fdfs_client包
import (
   "github.com/weilaihui/fdfs_client"
   "github.com/astaxie/beego"
)
上传单个文件到fdfs函数,设置三个返回值，组名，文件id，错误信息
func TestUploadByFilename(fileName string) (groupName string,FileId string,err error) {
    //连接fdfs通过client.conf文件
   fdfsClient,errClient:=fdfs_client.NewFdfsClient("conf/client.conf")
    //如果连不上就报错
   if errClient!=nil{
      beego.Info("New FdfsClient error %s",errClient.Error())
      return "","",errClient
   }
    //连上后，上传文件，返回一堆值，返回的有组名，文件id
   uploadResponse,errUpload:=fdfsClient.UploadByFilename(fileName)
    //如果上传不上去，就报错
   if errUpload!=nil{
      beego.Info("Upload FdfsClient error %s",errUpload.Error())
      return "","",errUpload
   }
    //返回组名和文件id，就是文件路径
   return uploadResponse.GroupName,uploadResponse.RemoteFileId,nil
}
```

在main.go里调用一下函数

```go
groupname,fileid,err:=models.TestUploadByFilename("static/images/home01.jpg")
beego.Info("groupname = ",groupname,"fileid = ",fileid,"err = ",err)
```

运行网页测试一下，返回的信息，能返回组名和文件路径.就说明上传成功了

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/cf0CBEl007.png?imageslim)

## 1.9 头像上传代码

先把刚才测试的上传函数在main.go里注释 掉吧。要不一直上传文件。

我们先测试一下项目的头像上传功能，看看能不能用。

打开首页，localhost:8899.点登录

输入用户名:11111111111密码111

然后登录，登录后点用户名

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/iLbDEcaKbJ.png?imageslim) 

然后点修改

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/984bija7KF.png?imageslim)

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/KDEfHKe241.png?imageslim)

然后再点选择文件，再点上传。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/Jl36Ah494H.png?imageslim)

发现右开发者工具里有报名的API请求。

user飘红是因为登录个人中心的用户数据没有获取到

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/KF4Am1iBfA.png?imageslim)

avatar是POST请求，因为上传头像请求没有请求到。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/gmdKa4G7Kc.png?imageslim)

user请求一会做，我们先做上传头像功能。用fastdfs接口去做。

肯定是要先去做一个路由。

```
/*
   上传头像
      Request URL: http://localhost:8899/api/v1.0/user/avatar
      Request Method: POST
   */
beego.Router("/api/v1.0/user/avatar", &controllers.UserController{},"post:PostAvatar")
```

好了。我们现在去写上传代码。打开controllers/user.go

加入一个函数，专门处理头像上传

关于上传功能，beego官方自带方法。

https://beego.me/docs/mvc/controller/params.md

```go
func (c *FormController) Post() {
    //返回值f是二进制，h是二进制的头，err是error
    //该方法主要用于用户读取表单中的文件名 the_file，然后返回相应的信息，用户根据这些变量来处理文件上传：过滤、保存文件等。
    //相当于os.openfile,返回的是一个文件句柄，得到文件句柄后才可以去读写操作文件。读写完后再close（）掉。这个其实也是一样的。
   f, h, err := c.GetFile("uploadname")
   if err != nil {
      log.Fatal("getfile err ", err)
   }
   defer f.Close()
   c.SaveToFile("uploadname", "static/upload/" + h.Filename) // 保存位置在 static/upload, 没有文件夹要先创建

}
```

就是我们点上传后，前端会传过来一个表单数据，我们主要获取是表单的名字，即name后面的avatar

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/mkK0Iimjbb.png?imageslim)

先看一下上传头像的设计文档

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/CjI291EE1H.png?imageslim)

设计要求返回一些数据给前端。

errno,errmsg就不说了。主要是data,需要返回的是avatar_url,value是一个由fdfs服务器网址和go上传完获取到的fileid拼接的这么一串网址。

失败返回errno 和errmsg就行了

我们再看一下业务流程图

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180621/6b2hhEiKdd.png?imageslim)

流程分析：

1.用户上传头像，发起请求给后台，POST

2.我们得到数据，就是this.GetFile("avatar"),返回fileData,headerData.

3.通过某方法得到文件后缀。

4.得到的文件存储在fastDFS上，得到fileid-url路径


>以前我们是调用的TestUploadByFile函数将文件存储到服务器上，只需要传过来文件名路径就可以，但是GetFile()函数返回的是fileData是一个multipart.File多进制数据buffer，需要存到数组里面。
这样的话我们就需要另外一个函数，TestUploadByBuffer()方法来上传了，即通过数组上传


5.通过session得到user_id,因为我们在登录和注册的时候设置了user_id。只需通过session拿到user_id

6.然后把fileid-url存到mysql数据库的user表对应的字段中。

7.把fileid-url和服务器域名拼接成完整的url路径，

8.打包成json返回给前端。

知道了流程就开始写代码

我们分析一下TestUploadByFile函数

```go
func TestUploadByBuffer(t *testing.T) {
   fdfsClient, err := NewFdfsClient("client.conf")
   if err != nil {
      t.Errorf("New FdfsClient error %s", err.Error())
      return
   }

   file, err := os.Open("testfile") // For read access.
    //到这之前都是为了获取文件句柄。来操作这个文件。
   if err != nil {
      t.Fatal(err)
   }

   var fileSize int64 = 0
   if fileInfo, err := file.Stat(); err == nil {
      fileSize = fileInfo.Size()
   }
   fileBuffer := make([]byte, fileSize)
   _, err = file.Read(fileBuffer)
   if err != nil {
      t.Fatal(err)
   }

   uploadResponse, err = fdfsClient.UploadByBuffer(fileBuffer, "txt")
   if err != nil {
      t.Errorf("TestUploadByBuffer error %s", err.Error())
   }

   t.Log(uploadResponse.GroupName)
   t.Log(uploadResponse.RemoteFileId)
   fdfsClient.DeleteFile(uploadResponse.RemoteFileId)
}
```

```
  fdfsClient, err := NewFdfsClient("client.conf")
   if err != nil {
      t.Errorf("New FdfsClient error %s", err.Error())
      return
   }

   file, err := os.Open("testfile") // For read access.

   if err != nil {
      t.Fatal(err)
   }
```
到这之前都是为了获取文件句柄。来操作这个文件。

后面都是用这个返回的file句柄来操作文件。

```
var fileSize int64 = 0
   if fileInfo, err := file.Stat(); err == nil {
      fileSize = fileInfo.Size()
   }
   fileBuffer := make([]byte, fileSize)
   _, err = file.Read(fileBuffer)
   if err != nil {
      t.Fatal(err)
   }
```

前面先获取文件长度，然后创建一个[]byte数据用来存二进制文件数据

然后file.Read读到的[]byte数据存到fileBuffer中。

上面那么长的处理，都是为了获得这个buffer数据

但是我们已经获得了，就不需再写这些了。

uploadResponse, err = fdfsClient.UploadByBuffer(fileBuffer, "txt") 

我们只需要用这行就行了。反这个拿过去。

```go
suffix:=path.Ext(hd.Filename)
	//4.得到的文件存储在fastDFS上，得到fileid-url路径，
	//连接到fdfs服务器
	fdfsClient,err:=fdfs_client.NewFdfsClient("../conf/client.conf")
	if err!=nil{
		resp["errno"]=models.RECODE_REQERR
		resp["errmsg"]=models.RecodeText(models.RECODE_REQERR)
		return
	}
	//创建hd.Size大小的[]byte数组用来存放fileData.Read读出来的[]byte数据
	fileBuffer:=make([]byte,hd.Size)
	//读出的数据存到[]byte数组中
	_,err=fileData.Read(fileBuffer)
	if err!=nil{
		resp["errno"]=models.RECODE_REQERR
		resp["errmsg"]=models.RecodeText(models.RECODE_REQERR)
		return
	}
	//把文件上传到fdfs上
uploadResponse, err := fdfsClient.UploadByBuffer(fileBuffer, suffix)
	if err != nil {
		beego.Error("TestUploadByBuffer error %s", err.Error())
	}
```

上面代码就实现了上传文件到fdfs服务器上。

刚才写代码的时候有个坑。官方的uploadResponse, err = fdfsClient.UploadByBuffer(fileBuffer, suffix)

的返回值err后面没有:号，这里要注意。我们要加上:号。因为有一个新的变量uploadResponse

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180622/3ehFhdc2F7.png?imageslim)

没:号就报红

我们测试下上传。看看上传成功没有

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180622/hCKd6aiAkj.png?imageslim)

上传完发现json没有返回值，是因为我们还没给前端返回json.这个后面会写

看一下beego终端显示的日志。获取到GroupName,RemoteFileId

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180622/AldFA539k6.png?imageslim)

看一下fdfs有没有文件。

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180622/DJIJG665gf.png?imageslim)

正确，现在我们继续实现后面的功能。

现在我们是获取用户session的user_id,这个好写

```
user_id:=this.GetSession("user_id")
```

现在实现一下把uploadBuffer返回的fileid写入到user表中的对应用户id的avatar_url字段中。这样用户就能显示头像了。这就是个更新的操作了

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180622/G89HCaLDib.png?imageslim)

看代码

```go
//创建一个user对象，用来往结构体中放数据
var user models.User
//获取数据库操作句柄
o:=orm.NewOrm()
//查询user表
qs:=o.QueryTable("user")
//查询id=user_id的（where id=user_id），查到的数据放到&user结构体中，这个user_id就是刚才GetSession获取到的
qs.Filter("id",user_id).One(&user)
//把图片的远程路径存到结构体中user.Avatar_url用户图片路径中
user.Avatar_url =uploadResponse.RemoteFileId
//将user结构体更新到数据库中
//(update user set user.Avatar_url =uploadResponse.RemoteFileId where where id=user_id)
_,errUpdate := o.Update(&user)
if errUpdate!=nil{
   resp["errno"]=models.RECODE_DBERR
   resp["errmsg"]=models.RecodeText(models.RECODE_DBERR)
   return
}
```

上面代码是实现了给用户添加fdfs返回来的文件路径，并更新到mysql中

接下来我们来实现把fileid和fdfs网址拼接成完整的url,就是下面这样的

http://10.0.151.220:9998/group1/M00/00/00/CgCX3FsrfyOABuA2AAFqdROOF2Y596.jpg

http://10.0.151.220:9998/+group1/M00/00/00/CgCX3FsrfyOABuA2AAFqdROOF2Y596.jpg

我们接一下拼接返回给前端的json格式

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180622/ADa054iDe3.png?imageslim)

要的是"data":{

​	"avatar_url":"http://10.0.151.220:9998/group1/M00/00/00/CgCX3FsrfyOABuA2AAFqdROOF2Y596.jpg"

}

```go
//7.把fileid-url和服务器域名拼接成完整的url路径
avatar_url:=make(map[string]string)
avatar_url["avatar_url"]="http://10.0.151.220:9998/"+uploadResponse.RemoteFileId
resp["data"]=avatar_url
```

测试一下上传可以不？

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180622/Gk3lAGiCgB.png?imageslim)

发现是可以的，没有问题。图片上传成功并显示，但是有个小问题。图片.jpg前面多加了一个.变成..jpg.发现是因为path.Ext()函数截取文件后缀名的时候截取到的是.jpg

然后我们上传到fdfs后，生成的文件名就变成文件名.+.jpg了。

所以我们在上传的时候把.jpg后缀用切片把.切掉。变成jpg，就好了。

suffix[1:]

```
uploadResponse, err := fdfsClient.UploadByBuffer(fileBuffer, suffix[1:])
```

测试 一下

![mark](http://p9ug71a1p.bkt.clouddn.com/blog/180622/DFDE362KKB.png?imageslim)

上传没有问题。

到这里上传头像功能已经可以正常使用了。

贴上完整代码

```go
//上传头像
func (this *UserController) PostAvatar()  {
   resp:=make(map[string]interface{})
   defer this.RetData(resp)

   //1.用户上传头像，发起请求给后台，POST

   //2.我们得到数据，就是this.GetFile("avatar"),返回fileData是数据,hd为form操作句柄
   fileData,hd,err:=this.GetFile("avatar")
   defer fileData.Close()
   if err!=nil{
      resp["errno"]=models.RECODE_REQERR
      resp["errmsg"]=models.RecodeText(models.RECODE_REQERR)
      return
   }
   //3.通过某方法得到文件后缀。
   /*
   一般我们通过方法headerData.Filename，能得到我们上传的文件的名字比如2.jpg,然后我们需要去得到这个文件的后缀
   一般如果用户上传的文件是a.jpg.avi.mp3这样，我们用go原生的字符串截取，只能得到.jpg这样的用户名。但是beego提供
   了一个专门用来截取后缀的现成的函数path.Ext()
   */
   suffix:=path.Ext(hd.Filename) //获取到的是.jpg，有点。下面把.去掉
   //去掉.jpg前面的，变成jpg
   suffixStr:=suffix[1:]
   //4.得到的文件存储在fastDFS上，得到fileid-url路径，
   //连接到fdfs服务器
   fdfsClient,err:=fdfs_client.NewFdfsClient("conf/client.conf")
   if err!=nil{
      resp["errno"]=models.RECODE_REQERR
      resp["errmsg"]=models.RecodeText(models.RECODE_REQERR)
      return
   }
   //创建hd.Size大小的[]byte数组用来存放fileData.Read读出来的[]byte数据
   fileBuffer:=make([]byte,hd.Size)
   //读出的数据存到[]byte数组中
   _,err=fileData.Read(fileBuffer)
   if err!=nil{
      resp["errno"]=models.RECODE_REQERR
      resp["errmsg"]=models.RecodeText(models.RECODE_REQERR)
      return
   }
   //把文件上传到fdfs上
   uploadResponse, err := fdfsClient.UploadByBuffer(fileBuffer, suffixStr)
   if err != nil {
      beego.Error("TestUploadByBuffer error %s", err.Error())
      resp["errno"]=models.RECODE_REQERR
      resp["errmsg"]=models.RecodeText(models.RECODE_REQERR)
      return
   }

   beego.Info(uploadResponse.GroupName)
   beego.Info(uploadResponse.RemoteFileId)
   //5.通过session得到user_id,因为我们在登录和注册的时候设置了user_id。只需通过session拿到user_id
   user_id:=this.GetSession("user_id")
   //6.然后把fileid-url存到mysql数据库的user表对应的字段中。
   //创建一个user对象，用来往结构体中放数据
   var user models.User
   //获取数据库操作句柄
   o:=orm.NewOrm()
   //查询user表
   qs:=o.QueryTable("user")
   //查询id=user.ID的，放到&user结构体中
   qs.Filter("id",user_id).One(&user)
   //把图片的远程路径存到结构体中user.Avatar_url用户图片路径中
   user.Avatar_url =uploadResponse.RemoteFileId
   //将user结构体更新到数据库中
   _,errUpdate := o.Update(&user)
   if errUpdate!=nil{
      resp["errno"]=models.RECODE_DBERR
      resp["errmsg"]=models.RecodeText(models.RECODE_DBERR)
      return
   }

   //7.把fileid-url和服务器域名拼接成完整的url路径
   avatar_url:=make(map[string]string)
   avatar_url["avatar_url"]="http://10.0.151.220:9998/"+uploadResponse.RemoteFileId
   resp["errno"]=models.RECODE_OK
   resp["errmsg"]=models.RecodeText(models.RECODE_OK)
   resp["data"]=avatar_url

   //8.打包成json返回给前端。

}
```

## 1.10 头像上传代码优化

我把头像上传到fdfs代码单独封装成函数了。以后就调用就可以了。

代码：controllers/fdfs.go

```
func UploadByBuffer(fileBuffer []byte,suffixStr string) (uploadResp *fdfs_client.UploadFileResponse,err error)  {
   resp:=make(map[string]interface{})
   //连接到fdfs服务器
   fdfsClient,err:=fdfs_client.NewFdfsClient("conf/client.conf")
   if err!=nil{
      resp["errno"]=models.RECODE_REQERR
      resp["errmsg"]=models.RecodeText(models.RECODE_REQERR)
      return nil,err
   }

   //把文件上传到fdfs上
   uploadResponse, err := fdfsClient.UploadByBuffer(fileBuffer, suffixStr)
   if err != nil {
      beego.Error("TestUploadByBuffer error %s", err.Error())
      resp["errno"]=models.RECODE_REQERR
      resp["errmsg"]=models.RecodeText(models.RECODE_REQERR)
      return nil,err
   }

   beego.Info(uploadResponse.GroupName)
   beego.Info(uploadResponse.RemoteFileId)
   return uploadResponse,nil
}
```

我们只需要传过来两个值，然后返回uploadResponse和err就行了。

然后在user.go里用uploadResponse调用方法就行了。

然后我上传完图片发现uploadResponse.RemoteFileId,返回的网址后面是\。

http://10.0.151.220:9998/group1/M00\00/00/CgCX3FssnPqANR2fAAFqdROOF2Y153.jpg

这个好解决。替换一下就行了。

```
uploadResponse,err:=UploadByBuffer(fileBuffer,suffixStr)
将\替换为/,-1是全部替换
RemoteFileId:=strings.Replace(uploadResponse.RemoteFileId,`\`,"/",-1)
```

然后下面插入数据库和拼接url的时候直接用RemoteFileId就行了。

user.go完整代码

```go
package controllers

import (
   "github.com/astaxie/beego"
   "encoding/json"
   "github.com/astaxie/beego/orm"
   "loveHome/models"
   "path"
   "strings"
)

type UserController struct {
   beego.Controller
}

func (this *UserController) RetData(resp map[string]interface{})  {
   this.Data["json"] = resp
   this.ServeJSON()
}
//用户注册
func (this *UserController) Reg() {
   resp:=make(map[string]interface{})
   defer this.RetData(resp)
   //获取前端传过来的json数据
   json.Unmarshal(this.Ctx.Input.RequestBody, &resp)
   /*
   这是传过来的数据
   mobile: "111"
   password: "111"
   sms_code: "111"
   */
   beego.Info(`resp["mobile"] = `,resp["mobile"])
   beego.Info(`resp["password"] = `,resp["password"])
   beego.Info(`resp["sms_code"] =`,resp["sms_code"])
   //插入数据库
   o:=orm.NewOrm()
   user:=models.User{} //啥数据不用传
   user.Password_hash=resp["password"].(string)
   user.Name=resp["mobile"].(string)
   user.Mobile=resp["mobile"].(string)
   //插入
   id,err:=o.Insert(&user)
   if err!=nil{
      resp["errno"]=models.RECODE_NODATA
      resp["errmsg"]=models.RecodeText(models.RECODE_NODATA)
      return
   }
   resp["errno"]=models.RECODE_OK
   resp["errmsg"]=models.RecodeText(models.RECODE_OK)
   beego.Info("reg succee ,id = ",id)
   //设置一个session,用来登录后显示用户名
   this.SetSession("name",user.Name)

}
//上传头像
func (this *UserController) PostAvatar()  {
   resp:=make(map[string]interface{})
   defer this.RetData(resp)

   //1.用户上传头像，发起请求给后台，POST

   //2.我们得到数据，就是this.GetFile("avatar"),返回fileData是数据,hd为form操作句柄
   fileData,hd,err:=this.GetFile("avatar")
   defer fileData.Close()
   if err!=nil{
      resp["errno"]=models.RECODE_REQERR
      resp["errmsg"]=models.RecodeText(models.RECODE_REQERR)
      return
   }
   //3.通过某方法得到文件后缀。
   /*
   一般我们通过方法headerData.Filename，能得到我们上传的文件的名字比如2.jpg,然后我们需要去得到这个文件的后缀
   一般如果用户上传的文件是a.jpg.avi.mp3这样，我们用go原生的字符串截取，只能得到.jpg这样的用户名。但是beego提供
   了一个专门用来截取后缀的现成的函数path.Ext()
   */
   suffix:=path.Ext(hd.Filename) //获取到的是.jpg，有点。下面把.去掉
   //去掉.jpg前面的，变成jpg
   suffixStr:=suffix[1:]
   //创建hd.Size大小的[]byte数组用来存放fileData.Read读出来的[]byte数据
   fileBuffer:=make([]byte,hd.Size)
   //读出的数据存到[]byte数组中
   _,err=fileData.Read(fileBuffer)
   if err!=nil{
      resp["errno"]=models.RECODE_REQERR
      resp["errmsg"]=models.RecodeText(models.RECODE_REQERR)
      return
   }
   //4.得到的文件存储在fastDFS上，得到fileid-url路径，
   uploadResponse,err:=UploadByBuffer(fileBuffer,suffixStr)
   RemoteFileId:=strings.Replace(uploadResponse.RemoteFileId,`\`,"/",-1)

   //5.通过session得到user_id,因为我们在登录和注册的时候设置了user_id。只需通过session拿到user_id
   user_id:=this.GetSession("user_id")
   //6.然后把fileid-url存到mysql数据库的user表对应的字段中。
   //创建一个user对象，用来往结构体中放数据
   var user models.User
   //获取数据库操作句柄
   o:=orm.NewOrm()
   //查询user表
   qs:=o.QueryTable("user")
   //查询id=user.ID的，放到&user结构体中
   qs.Filter("id",user_id).One(&user)
   //把图片的远程路径存到结构体中user.Avatar_url用户图片路径中
   user.Avatar_url =RemoteFileId
   //将user结构体更新到数据库中
   _,errUpdate := o.Update(&user)
   if errUpdate!=nil{
      resp["errno"]=models.RECODE_DBERR
      resp["errmsg"]=models.RecodeText(models.RECODE_DBERR)
      return
   }

   //7.把fileid-url和服务器域名拼接成完整的url路径
   avatar_url:=make(map[string]string)
   avatar_url["avatar_url"]="http://10.0.151.220:9998/"+RemoteFileId
   resp["errno"]=models.RECODE_OK
   resp["errmsg"]=models.RecodeText(models.RECODE_OK)
   resp["data"]=avatar_url

   //8.打包成json返回给前端。

}
```

fdfs.go完整代码

```go
package controllers

import (
   "github.com/weilaihui/fdfs_client"
   "github.com/astaxie/beego"
   "loveHome/models"
)

func TestUploadByFilename(fileName string) (groupName string,FileId string,err error) {
   fdfsClient,errClient:=fdfs_client.NewFdfsClient("conf/client.conf")
   if errClient!=nil{
      beego.Info("New FdfsClient error %s",errClient.Error())
      return "","",errClient
   }
   uploadResponse,errUpload:=fdfsClient.UploadByFilename(fileName)
   if errUpload!=nil{
      beego.Info("Upload FdfsClient error %s",errUpload.Error())
      return "","",errUpload
   }
   return uploadResponse.GroupName,uploadResponse.RemoteFileId,nil
}

func UploadByBuffer(fileBuffer []byte,suffixStr string) (uploadResp *fdfs_client.UploadFileResponse,err error)  {
   resp:=make(map[string]interface{})
   //连接到fdfs服务器
   fdfsClient,err:=fdfs_client.NewFdfsClient("conf/client.conf")
   if err!=nil{
      resp["errno"]=models.RECODE_REQERR
      resp["errmsg"]=models.RecodeText(models.RECODE_REQERR)
      return nil,err
   }

   //把文件上传到fdfs上
   uploadResponse, err := fdfsClient.UploadByBuffer(fileBuffer, suffixStr)
   if err != nil {
      beego.Error("TestUploadByBuffer error %s", err.Error())
      resp["errno"]=models.RECODE_REQERR
      resp["errmsg"]=models.RecodeText(models.RECODE_REQERR)
      return nil,err
   }

   beego.Info(uploadResponse.GroupName)
   beego.Info(uploadResponse.RemoteFileId)
   return uploadResponse,nil
}
```

第四天我们将学习更新用户名，实名认证，房屋信息上传。